apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: prometheus-operator
  name: prometheus-operator
spec:
  helmVersion: v3
  chart:
    type: helmrepo
    repository: https://prometheus-community.github.io/helm-charts
    name: kube-prometheus-stack
    version: 14.5.0
  releaseName: prometheus-operator
  targetNamespace: lma
  values:
    fullnameOverride: prometheus-operator
    defaultRules:
      create: false
    global:
      rbac:
        create: true
    alertmanager:
      enabled: false
    grafana:
      enabled: false
    kubeApiServer:
      enabled: false
    kubelet:
      enabled: false
    kubeControllerManager:
      enabled: false
    coreDns:
      enabled: false
    kubeDns:
      enabled: false
    kubeEtcd:
      enabled: false
    kubeScheduler:
      enabled: false
    kubeProxy:
      enabled: false
    kubeStateMetrics:
      enabled: false
#   kube-state-metrics: # subchart configuration
    nodeExporter:
      enabled: false
#   prometheus-node-exporter: # subchart configuration
    prometheusOperator:
      enabled: true
      nodeSelector: {}  # TO_BE_FIXED
      createCustomResource: true
      cleanupCustomResource: true
      cleanupCustomResourceBeforeInstall: true
    prometheus:
      enabled: false
  wait: true
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: prometheus
  name: prometheus
spec:
  helmVersion: v3
  chart:
    type: helmrepo
    repository: https://prometheus-community.github.io/helm-charts
    name: kube-prometheus-stack
    version: 14.5.0
  releaseName: prometheus
  targetNamespace: lma
  values:
    defaultRules:
      create: false
    global:
      rbac:
        create: true
    alertmanager:
      alertmanagerSpec:
        nodeSelector: {} # TO_BE_FIXED
        retention: TO_BE_FIXED
      config:
        global:
          slack_api_url: TO_BE_FIXED
          smtp_auth_password: null
          smtp_auth_username: null
          smtp_from: null
          smtp_smarthost: null
        receivers:
        - name: default-alert
          slack_configs:
          - channel: '#doj-noti'
            send_resolved: true
            text: |-
              {{ if or (and (eq (len .Alerts.Firing) 1) (eq (len .Alerts.Resolved) 0)) (and (eq (len .Alerts.Firing) 0) (eq (len .Alerts.Resolved) 1)) }}
                {{ range .Alerts.Firing }}{{ .Annotations.message }}{{ end }}{{ range .Alerts.Resolved }}{{ .Annotations.message }}{{ end }}
              {{ else }}
              {{ if gt (len .Alerts.Firing) 0 }}
              *Alerts Firing:*
                {{ range .Alerts.Firing }}- {{ .Labels.alertname  }}: {{ .Annotations.message }}
              {{ end }}{{ end }}
              {{ if gt (len .Alerts.Resolved) 0 }}
              *Alerts Resolved:*
                {{ range .Alerts.Resolved }}- {{ .Labels.alertname }}: {{ .Annotations.message }}
              {{ end }}{{ end }}
              {{ end }}
            title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ if or (and (eq (len .Alerts.Firing) 1) (eq (len.Alerts.Resolved) 0)) (and (eq (len .Alerts.Firing) 0) (eq (len .Alerts.Resolved) 1)) }} {{ range .Alerts.Firing }}{{ .Labels.alertname }}{{ end }}{{ range .Alerts.Resolved }}{{ .Labels.alertname }}{{ end }}{{ end }}'
            username: Prometheus
        - name: slack-alert
          slack_configs:
          - channel: '#doj-critical-alert' #FIXME
            send_resolved: true
            text: |-
              {{ if or (and (eq (len .Alerts.Firing) 1) (eq (len .Alerts.Resolved) 0)) (and (eq (len .Alerts.Firing) 0) (eq (len .Alerts.Resolved) 1)) }}
                {{ range .Alerts.Firing }}{{ .Annotations.message }}{{ end }}{{ range .Alerts.Resolved }}{{ .Annotations.message }}{{ end }}
              {{ else }}
              {{ if gt (len .Alerts.Firing) 0 }}
              *Alerts Firing:*
                {{ range .Alerts.Firing }}- {{ .Labels.alertname }}: {{ .Annotations.message }}
              {{ end }}{{ end }}
              {{ if gt (len .Alerts.Resolved) 0 }}
              *Alerts Resolved:*
                {{ range .Alerts.Resolved }}- {{ .Labels.alertname }}: {{ .Annotations.message }}
              {{ end }}{{ end }}
              {{ end }}
            title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ if or (and (eq (len .Alerts.Firing) 1) (eq (len.Alerts.Resolved) 0)) (and (eq (len .Alerts.Firing) 0) (eq (len .Alerts.Resolved) 1)) }} {{ range .Alerts.Firing }}{{ .Labels.alertname }}{{ end }}{{ range .Alerts.Resolved }}{{ .Labels.alertname }}{{ end }}{{ end }}'
            username: Prometheus
        - name: telegram-alert
          webhook_configs:
          - send_resolved: true
            url: http://prometheus-bot:9087/alert/-GROUP_ID
        route:
          group_by:
          - alertname
          group_wait: 10s
          receiver: default-alert
          repeat_interval: 1h
          routes:
          - group_by:
            - alertname
            match:
              severity: page
            receiver: slack-alert
      enabled: true
    grafana:
      enabled: false
    kubeApiServer:
      enabled: true
      serviceMonitor:
        interval: TO_BE_FIXED
    kubelet:
      enabled: false
    kubeControllerManager:
      enabled: false
    coreDns:
      enabled: true
      serviceMonitor:
        interval: TO_BE_FIXED
    kubeDns:
      enabled: false
      serviceMonitor:
        interval: TO_BE_FIXED
    kubeEtcd:
      enabled: true
      endpoints: [] # TO_BE_FIXED
      serviceMonitor:
        interval: TO_BE_FIXED
        caFile: /etc/prometheus/secrets/etcd-client-cert/etcd-ca
        certFile: /etc/prometheus/secrets/etcd-client-cert/etcd-client
        insecureSkipVerify: false
        keyFile: /etc/prometheus/secrets/etcd-client-cert/etcd-client-key
        scheme: https
        serverName: localhost
    kubeScheduler:
      enabled: false
    kubeProxy:
      enabled: true
      serviceMonitor:
        interval: TO_BE_FIXED
    kubeStateMetrics:
      enabled: false
#   kube-state-metrics: # subchart configuration
    nodeExporter:
      enabled: false
#   prometheus-node-exporter: # subchart configuration
    fullnameOverride: lma
    prometheusOperator:
      admissionWebhooks:
        enabled: false
      enabled: false
    prometheus:
      prometheusSpec:
        retention: TO_BE_FIXED
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: TO_BE_FIXED
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: TO_BE_FIXED
        externalLabels:
          taco_cluster: TO_BE_FIXED
        nodeSelector:
          taco-lma: TO_BE_FIXED
        replicas: 1
        ruleNamespaceSelector:
          matchLabels:
            name: lma
        ruleSelectorNilUsesHelmValues: false
        secrets:
        - etcd-client-cert
        serviceMonitorNamespaceSelector:
          matchLabels:
            name: lma
        serviceMonitorSelectorNilUsesHelmValues: false
        podMonitorNamespaceSelector:
          matchLabels:
            name: lma
        podMonitorSelectorNilUsesHelmValues: false
        thanos:
          version: v0.18.0
          objectStorageConfig:
            key: objstore.yml 
            name: TO_BE_FIXED # secret name
          minTime: -3h
      service:
        nodePort: 30008
        type: NodePort
      thanosService:
        enabled: true
        annotations: {}
        labels: {}
        portName: grpc
        port: 10901
        targetPort: "grpc"
        nodePort: 30901
        type: NodePort
        clusterIP: ""
  wait: true
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: eck-operator
  name: eck-operator
spec:
  helmVersion: v3
  chart:
    type: helmrepo
    repository: https://helm.elastic.co
    name: eck-operator
    version: 1.6.0
  releaseName: eck-operator
  targetNamespace: elastic-system
  values:
    installCRDs: true
    replicaCount: 1
    config:
      containerRegistry: docker.elastic.co
    internal:
      manifestGen: true
      kubeVersion: 1.18.8
      createOperatorNamespace: true
    softMultiTenancy:
      enabled: false
  wait: true
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: kube-state-metrics
  name: kube-state-metrics
spec:
  helmVersion: v3
  chart:
    type: helmrepo
    # repository: https://kubernetes.github.io/kube-state-metrics
    # --------------------------------------------------------------------
    # this repo is not working on 2021.1.6
    # several issues are opend for this
    #    - https://github.com/kubernetes/kube-state-metrics/issues/1331
    #    - https://github.com/kubernetes/kube-state-metrics/issues/1337
    #    - https://github.com/kubernetes/kube-state-metrics/issues/1342
    # so, i'll use bitnami before the issues are closed
    repository: https://charts.bitnami.com/bitnami
    name: kube-state-metrics
    # version: 2.9.4
    version: 1.1.3
  releaseName: kube-state-metrics
  targetNamespace: lma
  values:
    nodeSelector: {} # TO_BE_FIXED
  wait: true
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: prometheus-node-exporter
  name: prometheus-node-exporter
spec:
  helmVersion: v3
  chart:
    type: helmrepo
    repository: https://prometheus-community.github.io/helm-charts
    name: prometheus-node-exporter
    version: 1.11.2
  releaseName: prometheus-node-exporter
  targetNamespace: lma
  values:
    extraArgs:
    - --no-collector.hwmon
  wait: true
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: prometheus-pushgateway
  name: prometheus-pushgateway
spec:
  helmVersion: v3
  chart:
    type: helmrepo
    repository: https://prometheus-community.github.io/helm-charts
    name: prometheus-pushgateway
    version: 1.5.1
  releaseName: prometheus-pushgateway
  targetNamespace: lma
  values:
    service:
      nodePort: 30010
      type: NodePort
    nodeSelector: {} # TO_BE_FIXED
  wait: true
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: prometheus-process-exporter
  name: prometheus-process-exporter
spec:
  helmVersion: v3
  chart:
    type: helmrepo
    repository: https://openinfradev.github.io/helm-repo
    name: prometheus-process-exporter
    version: 0.1.4
    skipDepUpdate: true
  releaseName: prometheus-process-exporter
  targetNamespace: lma
  values:
    images:
      pull_policy: Always
    labels:
      process_exporter:
        process_selector_key: process-exporter
        process_selector_value: enabled
    pod:
      lifecycle:
        upgrades:
          daemonsets:
            process_exporter:
              max_unavailable: 30%
      mandatory_access_control:
        type: null
      tolerations:
        process_exporter:
          enabled: true
          tolerations:
          - key: node-role.kubernetes.io/master
            operator: Exists
          - key: node-role.kubernetes.io/node
            operator: Exists
    conf:
      processes: dockerd,kubelet,kube-proxy,ntpd
  wait: true
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: eck-resource
  name: eck-resource
spec:
  helmVersion: v3
  chart:
    type: helmrepo
    repository: https://openinfradev.github.io/helm-repo
    name: eck-resource
    version: 1.1.1
  releaseName: eck-resource
  targetNamespace: lma
  values:
    elasticsearch:
      version: 7.5.1
      adminPassword: TO_BE_FIXED
      enabled: true 
      count: 3        # FIXME
      http:
        service:
          spec:
            type: NodePort
            ports:
            - name: https
              nodePort: 30011
              targetPort: 9200
              port: 9200
      nodeSets:
        master:
          enabled: true
          nodeSelector: {} # TO_BE_FIXED
          count: 3
          javaOpts: TO_BE_FIXED
          limitCpu: TO_BE_FIXED
          limitMem: TO_BE_FIXED
          pvc:
            storageClassName: TO_BE_FIXED
            size: TO_BE_FIXED
        hotdata:
          enabled: true
          nodeSelector: {} # TO_BE_FIXED
          count: 3
          javaOpts: TO_BE_FIXED
          limitCpu: TO_BE_FIXED
          limitMem: TO_BE_FIXED
          pvc:
            storageClassName: TO_BE_FIXED
            size: TO_BE_FIXED
        warmdata:
          enabled: false # TO_BE_FIXED
          nodeSelector: {} # TO_BE_FIXED
          count: 2
          javaOpts: TO_BE_FIXED
          limitCpu: TO_BE_FIXED
          limitMem: TO_BE_FIXED
          pvc:
            storageClassName: TO_BE_FIXED
            size: TO_BE_FIXED
        client:
          enabled: true # TO_BE_FIXED
          nodeSelector: {} # TO_BE_FIXED
          count: TO_BE_FIXED
          javaOpts: TO_BE_FIXED
          limitCpu: TO_BE_FIXED
          limitMem: TO_BE_FIXED
          pvc:
            storageClassName: TO_BE_FIXED
            size: 0.5Gi
    kibana:
      version: 7.5.1
      enabled: true
      http:
        tls:
          selfSignedCertificate:
            disabled: true
        service:
          spec:
            type: NodePort
            ports:
            - name: http
              nodePort: 30001
              targetPort: 5601
              port: 5601
      limitCpu: TO_BE_FIXED
      limitMem: TO_BE_FIXED
      nodeSelector: {} # TO_BE_FIXED
  wait: true
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: grafana
  name: grafana
spec:
  helmVersion: v3
  chart:
    type: helmrepo
    repository: https://grafana.github.io/helm-charts
    name: grafana
    version: 6.17.4
  releaseName: grafana
  targetNamespace: lma
  values:
    adminPassword: password
    sidecar:
      dashboards:
        enabled: true
        label: grafana_dashboard
      datasources:
        enabled: true
        label: grafana_datasource
    service:
      type: NodePort
      nodePort: 30009
    persistence:
      enabled: true
      size: 10G #FIXME
      storageClassName: TO_BE_FIXED
    grafana.ini:
      plugins:
        vonage-status-panel: true
        grafana-piechart-panel: true
        devopsprodigy-kubegraf-app: true
    plugins:
    - vonage-status-panel
    - grafana-piechart-panel
    - devopsprodigy-kubegraf-app
  wait: true
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: fluentbit-operator
  name: fluentbit-operator
spec:
  helmVersion: v3
  chart:
    type: helmrepo
    repository: https://openinfradev.github.io/helm-repo
    name: fluentbit-operator
    version: 1.2.0
    skipDepUpdate: true
  releaseName: fluentbit-operator
  targetNamespace: lma
  values:
    containerRuntime: containerd
    global:
      base_cluster_url: TO_BE_FIXED   #FIXME
    fluentbitOperator:
      enabled: true
      createCustomResource: true
      cleanupCustomResource: true
      nodeSelector: {} # TO_BE_FIXED
      resources:
        limits:
          cpu: "2"
          memory: 200Mi
        requests:
          cpu: 100m
          memory: 20Mi
    fluentbit:
      enabled: false
    logExporter:
      enabled: true
      nodeSelector: {} # TO_BE_FIXED
      serviceMonitor:
        enabled: false
        interval: 1m
    image:
      hyperkube:
        tag: v1.17.6
  wait: true
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: fluentbit
  name: fluentbit
spec:
  helmVersion: v3
  chart:
    type: helmrepo
    repository: https://openinfradev.github.io/helm-repo
    name: fluentbit-operator
    version: 1.2.0
    skipDepUpdate: true
  releaseName: fluentbit
  targetNamespace: lma
  values:
    fullnameOverride: fluentbit-cr-taco
    global:
      base_cluster_url: TO_BE_FIXED   #FIXME
      nodeSelector: {} # TO_BE_FIXED
    fluentbitOperator:
      enabled: false
      createCustomResource: false
      cleanupCustomResource: false
    fluentbit:
      enabled: true
      clusterName: TO_BE_FIXED
      daemonset:
        spec:
          pod:
            tolerations:
            - key: node-role.kubernetes.io/master
              operator: Exists
            - key: node-role.kubernetes.io/node
              operator: Exists
      targetLogs:
      - name: dockerlog
        tag: kube.*
        path: /var/log/containers/*.log
        type: fluent
        index: container
        parser: docker
        memBufLimit: 20MB
        bufferChunkSize: 2M
        bufferMaxSize: 5M
        multi_index:
        - key: "$kubernetes['namespace_name']"
          value: "kube-system|lma|fed|argo|openstack"
          index: platform
      - name: syslog
        tag: syslog.*
        path: /var/log/messages
        type: syslog
        index: syslog
        parser: syslog-rfc5424
      - name: syslog-ubuntu
        tag: syslog.*
        path: /var/log/syslog
        type: syslog
        index: syslog
        parser: syslog-rfc5424
      outputs:
        es:
          enabled: true
          createuser: true
          elasticPasswordSecret: TO_BE_FIXED
          username: taco-fluentbit
          password: tacoword
          host: TO_BE_FIXED
          port: 9200
          template:
            enabled: true
            ilms:
            - name: hot-delete-14days
              json:
                policy:
                  phases:
                    hot:
                      actions:
                        rollover:
                          max_size: 30gb
                          max_age: 1d
                          max_docs: 5000000000
                        set_priority:
                          priority: 100
                    delete:
                      min_age: 14d
                      actions:
                        delete: {}
            - name: hot-delete-7days
              json:
                policy:
                  phases:
                    hot:
                      actions:
                        rollover:
                          max_size: 30gb
                          max_age: 1d
                          max_docs: 5000000000
                        set_priority:
                          priority: 100
                    delete:
                      min_age: 7d
                      actions:
                        delete: {}
            - name: hot-delete-3hour
              json:
                policy:
                  phases:
                    hot:
                      actions:
                        rollover:
                          max_size: 30gb
                          max_age: 1h
                          max_docs: 5000000000
                        set_priority:
                          priority: 100
                    delete:
                      min_age: 3h
                      actions:
                        delete: {}
            templates:
            - name: platform
              json:
                index_patterns: "platform*"
                settings:
                  refresh_interval: 30s
                  number_of_shards: 3
                  number_of_replicas: 1
                  index.lifecycle.name: hot-delete-14days
                  index.lifecycle.rollover_alias: platform
            - name: application
              json:
                index_patterns: "container*"
                settings:
                  refresh_interval: 30s
                  number_of_shards: 3
                  number_of_replicas: 1
                  index.lifecycle.name: hot-delete-3hour
                  index.lifecycle.rollover_alias: container
            - name: syslog
              json:
                index_patterns: "syslog*"
                settings:
                  refresh_interval: 30s
                  number_of_shards: 2
                  number_of_replicas: 1
                  index.lifecycle.name: hot-delete-14days
                  index.lifecycle.rollover_alias: syslog
        http:
          enabled: true
      exclude:
      - key: "$kubernetes['container_name']"
        value: kibana|elasticsearch|fluent-bit
      alerts:
        makeAlertRule: true
      nodeSelector: {} # TO_BE_FIXED
    logExporter:
      enabled: false
    image:
      hyperkube:
        tag: v1.17.6
  wait: true
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: addons
  name: addons
spec:
  helmVersion: v3
  chart:
    type: helmrepo
    repository: https://openinfradev.github.io/helm-repo
    name: lma-addons
    version: 1.6.0
  releaseName: addons
  targetNamespace: lma
  values:
    grafanaDashboard:
      enabled: true
      namespace: lma
      sidecar:
        datasources:
          prometheusAddress: "thanos-query:9090"
      istio:
        enabled: true
      jaeger:
        enabled: true
      tacoCustomDashboard:
        enabled: true
      ceph:
        enabled: false
      argocd:
        enabled: false
      argowf:
        enabled: false
    serviceMonitor:
      calico:
        enabled: true
        interval: TO_BE_FIXED
      processExporter:
        enabled: true
        interval: TO_BE_FIXED
        selector:
          matchLabels:
            application: process_exporter
            component: metrics
            release_group: prometheus-process-exporter
      istio:
        enabled: true
        interval: TO_BE_FIXED
      jaeger:
        enabled: true
        interval: TO_BE_FIXED
      grafana:
        enabled: true
        interval: TO_BE_FIXED
      argocd:
        enabled: true
        interval: TO_BE_FIXED
      argowf:
        enabled: true
        interval: TO_BE_FIXED
      ceph:
        enabled: false  #FIXME
        interval: TO_BE_FIXED
        mon_hosts: []
      kubeStateMetrics:
        enabled: true
      nodeExporter:
        enabled: true
      pushgateway:
        enabled: true
      kubelet:
        enabled: true
        interval: TO_BE_FIXED
      federations: [] # TO_BE_FIXED
    kibanaInit:
      enabled: true
      url: TO_BE_FIXED
    prometheusRules:
      aggregation:
        enabled: true
      alert:
        enabled: true
  wait: true
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: prometheus-adapter
  name: prometheus-adapter
spec:
  helmVersion: v3
  chart:
    type: helmrepo
    repository: https://prometheus-community.github.io/helm-charts
    name: prometheus-adapter
    version: 2.5.1
  releaseName: prometheus-adapter
  targetNamespace: lma
  values:
    prometheus:
      url: http://lma-prometheus
      port: 9090
    rules:
      default: false
    nodeSelector: {} # TO_BE_FIXED
  wait: true
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: kubernetes-event-exporter
  name: kubernetes-event-exporter
spec:
  helmVersion: v3
  chart:
    type: helmrepo
    repository: https://openinfradev.github.io/helm-repo
    name: kubernetes-event-exporter
    version: 1.0.0
  releaseName: kubernetes-event-exporter
  targetNamespace: lma
  values:
    conf:
      logLevel: error     # possible level: error, debug,
      logFormat: json
      default:
        hosts: [] # TO_BE_FIXED
        index: kube-events
        user: elastic
        password: tacoword
        additionalDefaultReceivers: []
      additionalRoutes: {}
      additionalReceivers: {}
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: taco-watcher
  name: taco-watcher
spec:
  helmVersion: v3 
  chart:
    type: helmrepo
    repository: https://openinfradev.github.io/helm-repo
    name: taco-watcher
    version: 0.1.0
  releaseName: taco-watcher
  targetNamespace: lma
  values:
    config:
      grafana:
        authkey: admin:password
      initDB: true
      kibana:
        authkey: elastic:tacoword
      password: password
      username: taco
    nodeSelector: {} # TO_BE_FIXED
    resources:
      storageClassName: TO_BE_FIXED
    service:
      nodePort: 32000
      port: 32000
      proxy_from: 32001
      proxy_to: 32009
      targetPort: 32000
      type: NodePort
  wait: true
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: thanos
  name: thanos
spec:
  helmVersion: v3
  chart:
    type: helmrepo
    repository: https://charts.bitnami.com/bitnami
    name: thanos
    version: 3.4.0
  releaseName: thanos
  targetNamespace: lma
  values:
    global:
      storageClass: local-path
    clusterDomain: TO_BE_FIXED
    existingObjstoreSecret: TO_BE_FIXED
    query:
      nodeSelector: {}
      dnsDiscovery:
        enabled: true
        sidecarsService: TO_BE_FIXED
        sidecarsNamespace: lma
    queryFrontend:
      enabled: false
      nodeSelector: {}
      service:
        type: TO_BE_FIXED
        http:
          port: 9090
          nodePort: TO_BE_FIXED
      config: |-
        type: IN-MEMORY
        config:
          max_size: TO_BE_FIXED
          max_size_items: TO_BE_FIXED
          validity: TO_BE_FIXED
      extraFlags: []
        # query-range.split-interval: TO_BE_FIXED
        # query-range.max-retries-per-request: TO_BE_FIXED
        # query-frontend.log-queries-longer-than: TO_BE_FIXED
    bucketweb:
      enabled: TO_BE_FIXED
      logLevel: info
      refresh: 30m
      timeout: 5m
      nodeSelector: {}
      service:
        type: ClusterIP
        http:
          port: 8080
    compactor:
      enabled: TO_BE_FIXED
      logLevel: info
      retentionResolutionRaw: TO_BE_FIXED
      retentionResolution5m: TO_BE_FIXED
      retentionResolution1h: TO_BE_FIXED
      consistencyDelay: TO_BE_FIXED
      resources:
        limits:
          memory: TO_BE_FIXED
          cpu: TO_BE_FIXED
      nodeSelector: {}
      service:
        type: ClusterIP
        http:
          port: 9090
      persistence:
        enabled: true
        accessModes:
          - ReadWriteOnce
        size: TO_BE_FIXED
      extraFlags: []
        # Compaction 수행 관련 커맨트
        # 아래와 같은 block stream들이 있을때
        # external_labels: {cluster="eu1", replica="1", receive="true", environment="production"}
        # external_labels: {cluster="eu1", replica="2", receive="true", environment="production"}
        # external_labels: {cluster="us1", replica="1", receive="true", environment="production"}
        # external_labels: {cluster="us1", replica="1", receive="true", environment="staging"}
        # --compact.enable-vertical-compaction 와 함께 --deduplication.replica-label="replica" 라고 설정하면 아래와 같이 compcation됨
        # external_labels: {cluster="eu1", receive="true", environment="production"} (2 streams, resulted in one)
        # external_labels: {cluster="us1", receive="true", environment="production"}
        # external_labels: {cluster="us1", receive="true", environment="staging"}
    storegateway:
      enabled: true
      logLevel: info
      nodeSelector: {}
      service:
        type: ClusterIP
        http:
          port: 9090
        grpc:
          port: 10901
      config: |-
        type: IN-MEMORY
        config:
          max_size: TO_BE_FIXED
          max_item_size: TO_BE_FIXED
      persistence:
        enabled: true
        accessModes:
          - ReadWriteOnce
        size: TO_BE_FIXED
      replicaCount: 1
      autoscaling:
        enabled: false
        #  minReplicas: 1
        #  maxReplicas: 11
        #  targetCPU: 50
        #  targetMemory: 50
    ruler:
      enabled: TO_BE_FIXED
      logLevel: info
      alertmanagers: [] # TO_BE_FIXED
      evalInterval: 1m
      config: TO_BE_FIXED
      replicaCount: 1
      updateStrategyType: RollingUpdate
      podManagementPolicy: OrderedReady
      nodeSelector: {}
      service:
        type: ClusterIP
        http:
          port: 9090
        grpc:
          port: 10901
      persistence:
        enabled: true
        accessModes:
          - ReadWriteOnce
        size: TO_BE_FIXED
    metrics:
      enabled: false
      serviceMonitor:
        enabled: false
    volumePermissions:
      enabled: false
    minio:
      enabled: true
      accessKey:
        password: TO_BE_FIXED
      secretKey:
        password: TO_BE_FIXED
      defaultBuckets: TO_BE_FIXED
      service:
        type: NodePort
        nodePort: 30002
      persistence:
        storageClass: TO_BE_FIXED
        accessMode: TO_BE_FIXED
        size: TO_BE_FIXED
  wait: true
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: thanos-config
  name: thanos-config
spec:
  helmVersion: v3
  chart:
    type: helmrepo
    repository: https://openinfradev.github.io/helm-repo
    name: thanos-config
    version: 0.1.3
  releaseName: thanos-config
  targetNamespace: lma
  values:
    objectStorage:
      enabled: true
      secretName: TO_BE_FIXED
      bucketName: TO_BE_FIXED
      endpoint: thanos-minio:9000
      access_key: TO_BE_FIXED
      secret_key: TO_BE_FIXED
    sidecarsService:
      enabled: false
      type: NodePort
      nodePort: 30007
      name: TO_BE_FIXED
      port: 30901
      endpoints: [] # TO_BE_FIXED
  wait: true
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  labels:
    name: prepare-etcd-secret
  name: prepare-etcd-secret
spec:
  helmVersion: v3
  chart:
    type: helmrepo
    repository: https://openinfradev.github.io/helm-repo
    name: prepare-etcd-secret
    version: 0.1.1
  releaseName: prepare-etcd-secret
  targetNamespace: lma
  values:
    etcd:
      certdir: /etc/kubernetes/pki/etcd
      certfile: ca.crt
      client_certfile: peer.crt
      client_keyfile: peer.key
    # master node의 label을 환경에 맞게 적어야함
    # ex) "node-role.kubernetes.io/master": "" 
    nodeSelector: {} # TO_BE_FIXED
    # master node에 taint가 있는 경우 필요
    # ex) - key: "node-role.kubernetes.io/master"
    #       effect: "NoSchedule"
    #       operator: "Exists"
    tolerations: [] # TO_BE_FIXED
